{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../common\"))\n",
    "import time\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import pynq\n",
    "from pynq import Xlnk\n",
    "from pynq import Overlay\n",
    "from pynq.mmio import MMIO\n",
    "#from preprocessing import Agent\n",
    "#from preprocessing import BATCH_SIZE\n",
    "#from preprocessing import get_image_path\n",
    "import dac_sdc\n",
    "from IPython.display import display\n",
    "\n",
    "team = 'FunnyRevolution'\n",
    "#agent = Agent(team)\n",
    "agent=dac_sdc.Team(team, batch_size = 500)\n",
    "#print(str(BATCH_SIZE))\n",
    "BATCH_SIZE=agent.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pynq/pl_server/device.py:594: UserWarning: Users will not get PARAMETERS / REGISTERS information through TCL files. HWH file is recommended.\n",
      "  warnings.warn(message, UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/pynq/lib/dma.py:200: UserWarning: Failed to find parameter c_sg_length_width; users should really use *.hwh files for overlays.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#OVERLAY_PATH = '/home/xilinx/jupyter_notebooks/spooNN/recthalfsqznet/deploy/submission/ultra96_v04.bit'\n",
    "#overlay = Overlay(OVERLAY_PATH)\n",
    "overlay = pynq.Overlay(agent.get_bitstream_path())\n",
    "dma = overlay.axi_dma_0\n",
    "WEIGHTS_FILE_NAME = 'weights_file_final.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got nn_ctrl!\n",
      "total_num_img: 7\n",
      "images_to_process_in_batch: 7\n",
      "Total processed images: 7\n",
      "Total time: 1.091902494430542 seconds\n",
      "Total energy: 4.14581728354 J\n"
     ]
    }
   ],
   "source": [
    "xlnk = Xlnk()\n",
    "nn_ctrl = MMIO(0xA0010000, length=1024)\n",
    "print('Got nn_ctrl!')\n",
    "#176, 320\n",
    "## Allocate Buffers\n",
    "MINIBATCH_SIZE = 20\n",
    "height = 176\n",
    "width = 320\n",
    "pixel_bits = 24\n",
    "pixels_per_line = 384/pixel_bits\n",
    "num_lines = int((height*width)/pixels_per_line)\n",
    "\n",
    "in_buffer1 = xlnk.cma_array(shape=(MINIBATCH_SIZE*num_lines, 64), dtype=np.uint8)\n",
    "in_buffer2 = xlnk.cma_array(shape=(MINIBATCH_SIZE*num_lines, 64), dtype=np.uint8)\n",
    "in_buffers = [in_buffer1, in_buffer2]\n",
    "\n",
    "fire1_num_out_lines = (height/4)*(width/4)*MINIBATCH_SIZE\n",
    "fire1_out_buffer = xlnk.cma_array(shape=(int(16*fire1_num_out_lines),), dtype=np.uint32)\n",
    "fire2_num_out_lines = (height/8)*(width/8)*MINIBATCH_SIZE\n",
    "fire2_out_buffer = xlnk.cma_array(shape=(int(16*fire2_num_out_lines),), dtype=np.uint32)\n",
    "fire3_num_out_lines = (height/16)*(width/16)*MINIBATCH_SIZE\n",
    "fire3_out_buffer = xlnk.cma_array(shape=(int(16*fire3_num_out_lines),), dtype=np.uint32)\n",
    "fire4_out_buffer = xlnk.cma_array(shape=(int(16*fire3_num_out_lines),), dtype=np.uint32)\n",
    "fire5_out_buffer = xlnk.cma_array(shape=(int(16*fire3_num_out_lines),), dtype=np.uint32)\n",
    "final_num_lines = int((height/16)*(width/16))\n",
    "bndboxes = [xlnk.cma_array(shape=(MINIBATCH_SIZE,final_num_lines,16), dtype=np.int32),\n",
    "            xlnk.cma_array(shape=(MINIBATCH_SIZE,final_num_lines,16), dtype=np.int32),\n",
    "            xlnk.cma_array(shape=(MINIBATCH_SIZE,final_num_lines,16), dtype=np.int32),\n",
    "            xlnk.cma_array(shape=(MINIBATCH_SIZE,final_num_lines,16), dtype=np.int32)]\n",
    "obj_array = np.zeros((MINIBATCH_SIZE,final_num_lines))\n",
    "\n",
    "## Allocate SW weight buffers and load from text file\n",
    "NUM_LAYERS = 3+4*4\n",
    "weights_file = open(WEIGHTS_FILE_NAME, \"r\")\n",
    "layer = 0\n",
    "total_iterations = np.zeros(NUM_LAYERS)\n",
    "for line in weights_file:\n",
    "    if \"layer\" in line:\n",
    "        temp = line.split(\": \")\n",
    "        layer = int(temp[1])\n",
    "    if \"total_iterations\" in line:\n",
    "        temp = line.split(\": \")\n",
    "        total_iterations[layer] = int(temp[1])\n",
    "weights_file.close()\n",
    "\n",
    "weightfactors_length = np.zeros(NUM_LAYERS)\n",
    "weightsfactors = []\n",
    "for i in range(0, NUM_LAYERS):\n",
    "    weightfactors_length[i] = int(total_iterations[i])\n",
    "    weightsfactors.append( xlnk.cma_array(shape=(int(16*weightfactors_length[i]),), dtype=np.uint32) )\n",
    "obj_factors = np.zeros(4)\n",
    "box_factors = np.zeros(4)\n",
    "    \n",
    "index = 0\n",
    "weights_file = open(WEIGHTS_FILE_NAME, \"r\")\n",
    "for line in weights_file:\n",
    "    if \"layer\" in line:\n",
    "        temp = line.split(\": \")\n",
    "        layer = int(temp[1])\n",
    "        index = 0\n",
    "    elif \"total_iterations\" not in line:\n",
    "        if \"obj_factor\" in line:\n",
    "            temp = line.split(' ')\n",
    "            obj_factors[int(temp[1])] = int(temp[2])\n",
    "        elif \"box_factor\" in line:\n",
    "            temp = line.split(' ')\n",
    "            box_factors[int(temp[1])] = int(temp[2])\n",
    "        else:\n",
    "            no0x = line.split('0x')[-1]\n",
    "            base = 1\n",
    "            while base < len(no0x):\n",
    "                part = no0x[-1*(base+8):-1*base]    \n",
    "                weightsfactors[layer][index*16 + int(base/8)] = int(part, 16)\n",
    "                base += 8\n",
    "            index += 1\n",
    "\n",
    "## Define transfer functions\n",
    "def weightsfactors_transfer(weightsfactors):\n",
    "    nn_ctrl.write(0x40, 13)\n",
    "    nn_ctrl.write(0x48, 0)\n",
    "    nn_ctrl.write(0x0, 0) # Reset\n",
    "    nn_ctrl.write(0x0, 1) # Deassert reset\n",
    "    dma.sendchannel.transfer(weightsfactors)\n",
    "    dma.sendchannel.wait()\n",
    "    \n",
    "def fire(inbuffer, outbuffer, \n",
    "         squeeze_din_w, squeeze_din_h,\n",
    "         expand_din_w, expand_din_h,\n",
    "         expand_din_w_afterpool, expand_din_h_afterpool,\n",
    "         whichfire):\n",
    "    nn_ctrl.write(0x0, 0) # Reset\n",
    "    nn_ctrl.write(0x10, int(squeeze_din_w))\n",
    "    nn_ctrl.write(0x18, int(squeeze_din_h))\n",
    "    nn_ctrl.write(0x20, int(expand_din_w))\n",
    "    nn_ctrl.write(0x28, int(expand_din_h))\n",
    "    nn_ctrl.write(0x30, int(expand_din_w_afterpool))\n",
    "    nn_ctrl.write(0x38, int(expand_din_h_afterpool))\n",
    "    nn_ctrl.write(0x40, whichfire)\n",
    "    nn_ctrl.write(0x48, MINIBATCH_SIZE) # set numReps\n",
    "    nn_ctrl.write(0x0, 1) # Deassert reset\n",
    "    dma.recvchannel.transfer(outbuffer)\n",
    "    dma.sendchannel.transfer(inbuffer)\n",
    "\n",
    "## Inference (Main Part)\n",
    "interval_time = 0\n",
    "total_time = 0\n",
    "total_energy = 0\n",
    "total_num_img = len(agent.img_list)\n",
    "result = np.zeros((int(total_num_img), 17))\n",
    "agent.reset_batch_count()\n",
    "rails = pynq.get_rails()\n",
    "print('total_num_img: ' + str(total_num_img))\n",
    "\n",
    "processed_images = 0\n",
    "for i in range(math.ceil(total_num_img/BATCH_SIZE)):\n",
    "    # get a batch from agent\n",
    "    #batch = agent.send(interval_time, agent.img_batch)\n",
    "    batch = agent.get_next_batch()\n",
    "    sorted_batch = sorted(batch)\n",
    "    images_to_process_in_batch = len(sorted_batch)\n",
    "    print('images_to_process_in_batch: ' + str(images_to_process_in_batch))\n",
    "    minibatches_to_process = math.ceil(images_to_process_in_batch/MINIBATCH_SIZE)\n",
    "    \n",
    "    for k in range(0, minibatches_to_process):\n",
    "        size = MINIBATCH_SIZE\n",
    "        next_size = MINIBATCH_SIZE\n",
    "        if k == minibatches_to_process-1:\n",
    "            size = images_to_process_in_batch - k*MINIBATCH_SIZE\n",
    "        if k+1 == minibatches_to_process-1:\n",
    "            next_size = images_to_process_in_batch - (k+1)*MINIBATCH_SIZE\n",
    "#         print('size: ' + str(size))\n",
    "#         print('next_size: ' + str(next_size))\n",
    "#         print('Already processed: ' + str(processed_images))\n",
    "#         print('Process ' + str(size) + ' images, out of ' + str(images_to_process_in_batch) + ' in batch.')\n",
    "        \n",
    "        start = time.time()\n",
    "        recorder = pynq.DataRecorder(rails['5V'].power)\n",
    "        with recorder.record(0.01):\n",
    "            if k == 0:\n",
    "                for i in range(0, size):\n",
    "                    first_image = sorted_batch[k*MINIBATCH_SIZE + i]\n",
    "                    #image = cv2.imread(get_image_path(first_image))\n",
    "                    #image= cv2.imread(agent.get_next_batch()[k*MINIBATCH_SIZE + i])\n",
    "                    image = cv2.imread(str(first_image))\n",
    "                    image = cv2.resize(image, (width, height), interpolation=cv2.INTER_NEAREST)  \n",
    "                    in_buffers[k%2][i*num_lines:(i+1)*num_lines,0:48] = np.reshape(image, (num_lines, 48))\n",
    "\n",
    "#             stamp1 = time.time()\n",
    "\n",
    "            weightsfactors_transfer(weightsfactors[0])\n",
    "            fire(in_buffers[k%2], fire1_out_buffer,\\\n",
    "                width/2, height/2, width/2, height/2, width/4, height/4, 1)\n",
    "            if k < minibatches_to_process-1:\n",
    "                num_images_to_read = int(next_size*0.8)\n",
    "                for i in range(0, num_images_to_read):\n",
    "                    first_image = sorted_batch[(k+1)*MINIBATCH_SIZE + i]\n",
    "                    #image = cv2.imread(get_image_path(first_image))\n",
    "                    image = cv2.imread(str(first_image))\n",
    "                    #image= cv2.imread(agent.get_next_batch()[k*MINIBATCH_SIZE + i])\n",
    "                    image = cv2.resize(image, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "                    in_buffers[(k+1)%2][i*num_lines:(i+1)*num_lines,0:48] = np.reshape(image, (num_lines, 48))\n",
    "            dma.recvchannel.wait()\n",
    "\n",
    "#             stamp2 = time.time()\n",
    "\n",
    "            weightsfactors_transfer(weightsfactors[1])\n",
    "            fire(fire1_out_buffer, fire2_out_buffer,\\\n",
    "                width/4, height/4, width/4, height/4, width/8, height/8, 2)\n",
    "            if k < minibatches_to_process-1:\n",
    "                num_images_to_read = int(next_size*0.8)\n",
    "                for i in range(num_images_to_read, next_size-1):\n",
    "                    first_image = sorted_batch[(k+1)*MINIBATCH_SIZE + i]\n",
    "                    #image = cv2.imread(get_image_path(first_image))\n",
    "                    image = cv2.imread(str(first_image))\n",
    "                    #image= cv2.imread(agent.get_next_batch()[k*MINIBATCH_SIZE + i])\n",
    "                    image = cv2.resize(image, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "                    in_buffers[(k+1)%2][i*num_lines:(i+1)*num_lines,0:48] = np.reshape(image, (num_lines, 48))\n",
    "            dma.recvchannel.wait()\n",
    "\n",
    "#             stamp3 = time.time()\n",
    "\n",
    "            weightsfactors_transfer(weightsfactors[2])\n",
    "            fire(fire2_out_buffer, fire3_out_buffer,\\\n",
    "                width/8, height/8, width/8, height/8, width/16, height/16, 3)\n",
    "            if k < minibatches_to_process-1:\n",
    "                i = next_size-1\n",
    "                first_image = sorted_batch[(k+1)*MINIBATCH_SIZE + i]\n",
    "                #image = cv2.imread(get_image_path(first_image))\n",
    "                image = cv2.imread(str(first_image))\n",
    "                #image= cv2.imread(agent.get_next_batch()[k*MINIBATCH_SIZE + i])\n",
    "                image = cv2.resize(image, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "                in_buffers[(k+1)%2][i*num_lines:(i+1)*num_lines,0:48] = np.reshape(image, (num_lines, 48))\n",
    "            dma.recvchannel.wait()\n",
    "\n",
    "#             stamp4 = time.time()\n",
    "    \n",
    "            for t in range(0, 4):\n",
    "                weightsfactors_transfer(weightsfactors[3 + t*4])\n",
    "                fire(fire3_out_buffer, fire4_out_buffer,\\\n",
    "                    width/16, height/16, width/16, height/16, width/16, height/16, 4)\n",
    "                dma.recvchannel.wait()\n",
    "\n",
    "                weightsfactors_transfer(weightsfactors[4 + t*4])\n",
    "                fire(fire4_out_buffer, fire5_out_buffer,\n",
    "                    width/16, height/16, width/16, height/16, width/16, height/16, 5)\n",
    "                dma.recvchannel.wait()\n",
    "\n",
    "                weightsfactors_transfer(weightsfactors[5 + t*4])\n",
    "                fire(fire5_out_buffer, fire4_out_buffer,\\\n",
    "                    width/16, height/16, width/16, height/16, width/16, height/16, 6)\n",
    "                dma.recvchannel.wait()\n",
    "\n",
    "                weightsfactors_transfer(weightsfactors[6 + t*4])\n",
    "                fire(fire4_out_buffer, bndboxes[t],\\\n",
    "                    width/16, height/16, width/16, height/16, width/16, height/16, 7)\n",
    "                dma.recvchannel.wait()\n",
    "                \n",
    "                temp_obj = np.multiply(np.divide(bndboxes[t][:,:,4],float((1<<16))), float(obj_factors[t]))\n",
    "                if t == 0:\n",
    "                    obj_array = temp_obj\n",
    "                else:\n",
    "                    obj_array = np.add(obj_array, temp_obj)\n",
    "            \n",
    "#             stamp5 = time.time()\n",
    "        \n",
    "            grid_cell = np.argmax(obj_array, axis=1)\n",
    "            result[processed_images:processed_images+size,16] = grid_cell[0:size]\n",
    "            for p in range(0, size):\n",
    "                for t in range(0,4):\n",
    "                    result[processed_images+p, t*4:(t+1)*4] = bndboxes[t][p,grid_cell[p],0:4]\n",
    "        \n",
    "        end = time.time()\n",
    "        t = end - start\n",
    "        energy = recorder.frame[\"5V_power\"].mean() * t\n",
    "        \n",
    "#         print('IM read time: ' + str(stamp1-start))\n",
    "#         print('fire1 time: ' + str(stamp2-stamp1))\n",
    "#         print('fire2 time: ' + str(stamp3-stamp2))\n",
    "#         print('fire3 time: ' + str(stamp4-stamp3))\n",
    "#         print('firefinal time: ' + str(stamp5-stamp4))\n",
    "#         print('postprocessing time: ' + str(end-stamp5))\n",
    "#         print('Processing time: {} seconds.'.format(t))\n",
    "#         print('Energy: {} J.'.format(energy))\n",
    "        total_time += t\n",
    "        total_energy += energy\n",
    "        processed_images += size\n",
    "        \n",
    "print('Total processed images: ' + str(processed_images))\n",
    "print('Total time: ' + str(total_time),\"seconds\")\n",
    "#print('FPS: ' + str(processed_images/total_time))\n",
    "print('Total energy: ' + str(total_energy),'J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "XML results written successfully.\n"
     ]
    }
   ],
   "source": [
    "#with open(agent.coord_team + '/{}.txt'.format(team), 'w+') as fcoord:\n",
    "#    for i in range(0,result.shape[0]):\n",
    "#        fcoord.write(str(result[i,:]))\n",
    "#        fcoord.write('\\n')\n",
    "#print(\"Coordinate results written successfully.\")\n",
    "\n",
    "written_count = 0\n",
    "result_rectangles = []\n",
    "for i in range(0,result.shape[0]):\n",
    "    float_objdetect = result[i,16].astype('float')\n",
    "    float_bndboxes1 = np.multiply(np.divide(result[i,0:4].astype('float'), float((1<<16))), float(box_factors[0]))\n",
    "    float_bndboxes2 = np.multiply(np.divide(result[i,4:8].astype('float'), float((1<<16))), float(box_factors[1]))\n",
    "    float_bndboxes3 = np.multiply(np.divide(result[i,8:12].astype('float'), float((1<<16))), float(box_factors[2]))\n",
    "    float_bndboxes4 = np.multiply(np.divide(result[i,12:16].astype('float'), float((1<<16))), float(box_factors[3]))\n",
    "    float_bndboxes = float_bndboxes1+float_bndboxes2+float_bndboxes3+float_bndboxes4\n",
    "    float_bndboxes = np.divide( float_bndboxes, 4.0*float((1 << 22)) )\n",
    "    \n",
    "    obj_h = int(float_objdetect/(width/16))\n",
    "    obj_w = int(float_objdetect%(width/16))\n",
    "        \n",
    "    x_min = int((float_bndboxes[0] + obj_w*16) *(640/width))\n",
    "    y_min = int((float_bndboxes[1] + obj_h*16) *(360/height))\n",
    "    x_max = int((float_bndboxes[2] + obj_w*16) *(640/width))\n",
    "    y_max = int((float_bndboxes[3] + obj_h*16) *(360/height))\n",
    "\n",
    "    result_rectangles.append([x_min, x_max, y_min, y_max])\n",
    "        \n",
    "print(str(len(result_rectangles)))\n",
    "agent.save_results_xml(result_rectangles, total_time, total_energy)\n",
    "print(\"XML results written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnk.xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
